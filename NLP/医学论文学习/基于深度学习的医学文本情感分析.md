
# 准备工作

## Deep	Learning	for	Sentiment	Analysis:	A	Survey

Sentiment analysis
人们对产品、服务、组织、个人、问题、事件、主题及其属性等实体的意见、情绪、情感、评价和态度的计算研究。

观点是人类活动的核心也是每个人行为的关键影像因素
每个人的行动和选择很大程度上取决于别人如何看待和评价世界
个人如此，组织也是如此

近年来，我们目睹社交媒体上的固执己见的帖子帮助重塑了企业，影响了公众的情绪和情绪，这对我们的社会和政治体系产生了深远的影响。此类帖子还动员了群众进行政治变革，例如2011年在一些阿拉伯国家发生的政治变革。因此，收集和研究意见成为必要1。

由于不同网站的激增，在网络上查找和监控意见网站并提取其中包含的信息仍然是一项艰巨的任务。每个网站通常都包含*大量的观点文本*，这些文本在长博客和论坛帖子中*并不总是容易被解读*。一般的*人类读者很难识别相关网站并提取和总结其中的观点*。因此需要*自动情绪分析系统*。正因为如此，有许多初创公司*专注于提供情感分析服务*。许多大公司也建立了自己的内部能力。这些实际应用和工业利益为情感分析的研究提供了强大的动力。

现有的研究已经产生了许多用于情感分析各种任务的技术，其中包括*监督和无监督*方法。
在监督环境中，早期论文使用了各种类型的监督机器学习方法（例如支持向量机（SVM）、最大熵、朴素贝叶斯等）和特征组合。

无监督方法包括利用情感词典、语法分析和句法模式的各种方法。已经出版了几本调查书籍和论文，广泛涵盖了这些早期的方法和应用。1,2,3 

大约十年前，深度学习已经成为一种强大的机器学习技术4，并在以下领域产生了最先进的结果：许多应用领域，*从计算机视觉和语音识别到自然语言处理*。将深度学习*应用于情感分析最近也变得非常流行*。本文首先对深度学习进行了概述，然后对基于深度学习的情感分析研究进行了全面的综述。


神经网络的复兴可以归因于许多因素。最重要的包括：(1) 由于硬件（例如 GPU）的进步而获得的计算能力，(2) 大量训练数据的可用性，以及 (3) 学习中间表示的能力和灵活性。 

### 研究任务
#### 文档级别

将有观念的文档（例如产品评论）分类为表达总体正面或负面意见。它将整个文档视为基本信息单元，并假设该文档已知是固执己见的并且包含有关单个实体（例如特定电话）的意见。

#### 句子级别

句子级情感分类对文档中的各个句子进行分类。然而，不能认为每句话都是有观念的。传统上，人们常常首先将一个句子分类为有观念和无观念，这称为主观性分类。然后将所得的有 i 观念的句子分类为表达积极或消极意见。

句子级情感分类也可以表述为三类分类问题，即将句子分类为中性、积极或消极。
#### 方面级别

与文档级和句子级情感分析相比，方面级情感分析或基于方面的情感分析更加细粒度。

它的任务是*提取和总结人们对实体和实体的方面/特征表达的意见*，这些意见也称为*目标(target)*。例如，在产品评论中，它的目的是分别总结对产品不同方面的正面和负面意见，尽管对产品的总体情绪可能是正面的，也可能是负面的。

基于方面的情感分析的整个任务由*方面提取、实体提取和方面情感分类*等几个子任务组成。例如，从“iPhone的语音质量很棒，但电池很糟糕”这句话中，实体提取应将“iPhone”识别为实体，而方面提取应识别“语音质量”和“电池”是两个方面。方面情感分类应该将对 iPhone 的语音质量表达的情感分类为正面，而将 iPhone 的电池表达的情感分类为负面。

请注意，为了简单起见，在大多数算法中，*方面提取和实体提取结合在一起*，称为方面提取或情感/意见目标提取。

---

除了这些核心任务之外，情感分析还研究情感分析、讽刺检测、多语言情感分析等。



### 方面级别的感情分析

同时考虑情感和目标的信息，因为对于不同目标有不同的情感

目标通常是一个实体或者实体的某一方面

通常给定一个句子和一个目标方面，判断不同的情感

方面级别的情感分类具有挑战性，因为对目标与其周围上下文单词的语义相关性进行建模很困难。不同的上下文词对句子对目标的情感极性有不同的影响。因此，在使用神经网络构建学习模型时，有必要捕获*目标词和上下文词之间的语义联系*。

有三个重要任务。第一个任务是*表示目标的上下文*，其中上下文是指句子或文档中的上下文单词。这个问题可以使用上面两节中提到的*文本表示方法来类似地解决*。第二个任务是*生成一个目标表示，它可以与其上下文正确交互*。通用的解决方案是学习目标嵌入，这与词嵌入类似。第三个任务是*识别指定目标的重要情感上下文*（单词）。例如，在“iPhone的屏幕很清晰，但电池寿命很短”这句话中，“清晰”是“屏幕”的重要上下文词，“短”是“电池寿命”的重要上下文词。这项任务最近由注意力机制解决。尽管已经提出了许多深度学习技术来处理方面级别的情感分类，但据我们所知，文献中仍然没有占主导地位的技术。

#### 现有成果

Dong 等人提出了一种用于目标相关推特情感分类的*自适应递归神经网络*（AdaRNN），它学习根据上下文和句法结构向目标传播单词的情感。它使用根节点的表示作为特征，并将它们输入到 softmax 分类器中来预测类的分布。

Vo和Zhang69利用丰富的*自动特征*研究了基于方面的Twitter情感分类，这些自动特征是使用*无监督学习方法获得的附加特征*。该论文表明，*多重嵌入、多重池化函数和情感词典*可以提供丰富的特征信息源，并有助于实现*性能提升*。

由于 LSTM 可以以更灵活的方式捕获目标与其上下文单词之间的语义关系，Tang 等人70 提出了*目标相关 LSTM（TD-LSTM）和目标连接 LSTM（TC-LSTM）*，通过将目标考虑在内。他们将给定的目标视为一个特征，并将其与上下文特征连接起来进行方面情感分类。

Ruder 等人71 提出使用*分层和双向 LSTM 模型*进行方面级别的情感分类，该模型能够利用*句子内和句子间的关系*。评论中对句子及其结构的唯一依赖使得所提出的模型与语言无关。词嵌入被输入到句子级双向 LSTM 中。*前向和后向 LSTM 的最终状态与目标嵌入连接在一起*，并输入到双向审查级 LSTM 中。在每个时间步，前向和后向 LSTM 的输出都会被连接并输入到最后一层，该层输出情绪的概率分布。

考虑到 Dong 等人 68 以及 Vo 和 Zhang 69 工作的局限性，Zhang 等人 72 提出了一种句子级神经模型来解决池化函数的弱点，该模型没有明确地建模推文级语义。为了实现这一点，提出了两个*门控神经网络*。首先，使用双向门控神经网络连接推文中的单词，以便可以在隐藏层而不是单词上应用池化函数，以更好地表示目标及其上下文。其次，使用三路门控神经网络结构来对目标提及与其周围上下文之间的交互进行建模，通过使用门控神经网络结构来建模所包含推文的语法和语义以及之间的交互来解决局限性。分别是周围环境和目标。门控神经网络已被证明可以通过更好的梯度传播来减少标准循环神经网络对序列末端的偏差。

Wang 等人73 提出了一种具有*目标嵌入的基于注意力的 LSTM 方法*，该方法被证明是一种*强制神经模型关注句子相关部分*的有效方法。注意力机制用于强制模型关注句子的重要部分，以响应特定方面。同样，Yang 等人74 提出了两种基于注意力的双向 LSTM 来提高分类性能。 Liu 和Zhang75 通过区分从给定目标/方面的左上下文和右上下文获得的注意力来扩展注意力模型。他们通过添加多个门进一步控制了他们的注意力贡献。

Tang 等人76 引入了一种用于方面级别情感分类的*端到端记忆网络*，该网络采用具有*外部记忆的注意机制*来捕获每个上下文单词相对于*给定目标方面的重要性*。在推断方面的情感极性时，这种方法明确地捕获了每个上下文单词的重要性。这种重要性程度和文本表示是通过多个计算层计算的，每个计算层都是外部存储器上的神经注意模型。

Lei 等人77 提议使用*神经网络方法提取输入文本片段作为评论评级的基本原理*（原因）。该模型由*生成器和解码器*组成。生成器指定可能的基本原理（提取的文本）的*分布*，编码器将任何此类文本*映射到特定于任务的目标向量*。对于多方面情感分析，目标向量的每个坐标表示与相关方面相关的响应或评级。

Li等人78将*目标识别任务集成到情感分类任务*中，以更好地建模方面情感交互。他们表明，情感识别可以通过端到端机器学习架构来解决，其中两个子任务由深度记忆网络交织。这样，目标检测中产生的*信号为极性分类提供线索*，反过来，*预测的极性为目标识别提供反馈*。

Ma 等人79 提出了一种*交互式注意力网络*（IAN），它同时考虑了目标和上下文的注意力。也就是说，它使用两个注意力网络来交互地检测目标表达/描述的重要单词及其完整上下文的重要单词。

Chen 等人 80 提出利用*循环注意力网络*来更好地捕捉复杂上下文的情感。为了实现这一目标，他们提出的模型使用循环/动态注意力结构并学习 GRU 中注意力的非线性组合。 

Tay 等人 81 设计了一个二元记忆网络 (DyMemNN)，通过使用神经张量组合或全息组合进行记忆选择操作，对方面和上下文之间的二元交互进行建模。


