
# 1 定义
研究的问题或数据集包括多种模态信息 MultiModel Machine Learning
模态：表达或感知事物的方式，语音视频文字、雷达红外等
同一媒介下可存在不同的模态，两种不同语言、不同环境下采集的数据也可以是多模态

## 1.2 多模态
3V： Verbal Vocal Visual
![[Pasted image 20240302205210.png|425]]
1. 描述同一对象的多媒体数据；
2. 来自不同传感器的同一类媒体数据（常见于医学，B 超、CT 等，心跳、血压等）
3. 具有不同数据结构特点、表示形式的表意符号与信息。（描述同一对象的结构化、非结构化的数据单元；描述同一数学概念的公式、逻辑、符号、函数等；描述同一语义的词向量、知识图谱以及其他语义符号单元）
## 1.3 多模态学习
对多源异构数据的挖掘分析可以被理解为多模态学习
大数据：数据形式是固定的，从数据中获取信息
多模态：需要把原始数据转换成数字化

# 2 发展历史
深度学习时代：大规模数据集，GPU 快速计算，强大的视觉特征抽取能力，强大的语言特征抽取能力

![[Pasted image 20240302205522.png|500]]

# 3 典型任务
1. 图像、视频、语言预训练；跨任务预训练
2. text to speech; audio captioning给定语音生成总结
3. 目前缺少语音信号的同步处理，视频通常采样几帧，但是音频做采样会失真![[Pasted image 20240302210425.png]]
4. 最典型任务之一
![[Pasted image 20240302210552.png]]从文本到图像会比较难，文本是抽象的，图像是具象的；
目前多轮对话缺少记忆性，并且目前回答生硬，需要语料库足够丰富的相关性
6. ![[Pasted image 20240302211333.png]]
# 4 技术挑战
 representation提取文本、图像等内容背后的抽象信息、语义信息
 alignment将一维、二维的各种信息对齐
 translation（图像到文本、文本到语音、语音到....）
 fusion 两个输入的 embedding 放到一起
	 翻译与融合的并列：要知道文本对应的具体图片或者图片对应的具体文本，
 co-learning 协同学习（跨模态任务既要学习文本、又要学习图像，可以理解为多个任务的学习）
![[Pasted image 20240419203943.png]]
## 4.1 表征 Representation（metric learning）
学习如何利用多种模态的互补性和冗余性，表示总结多种数据
 多模态数据的异质性是的构建这样的表示具有挑战性
 浅层提取具象特征，越到深层提取的越抽象
 表征目的是让机器能够理解我们的信息，多模态特征是利用多模态之间的互补性，让机器学习到更好的特征表示
 ![[Pasted image 20240419205733.png]]
方法 A：把两个特征做一个 concatenate或者 add，前者改变维度，后者不变。
方法 B：辅助性互相影响的学习，两个特征是独特的，但是会做相似性度量、学习。
比如一路做一个图像特征、一路做一个文本特征，然后将其特征表示做距离度量，使得同一类的图文之间距离更近。
### 4.1.1 方法 A：联合表征
将多个模态的信息一起映射到一个统一的多模态向量空间中。
Joint 结构注重捕捉多模态之间的互补性。

![[Pasted image 20240419210920.png|450]]

Mutimodel learning with deep boltzman machines(NIPS 2012)提出将 DBM（深度玻尔兹曼学习器） 结构扩充到多模态领域。（传统的机器学习方法）
在应用阶段：输入图片，机器能利用条件概率，输出对应的文字描述；输入文字，给出对应的图片。



### 4.1.2 方法 B 协同表征
（大多数人会选择）两路之间互不干扰，将每个模态映射到各自的表示空间，映射后的向量之间满足一定的相关性约束（如线性相关）
不寻求融合，而是建模多种模态数据之间的相关性
![[Pasted image 20240419213019.png|600]]

网络表示 X1与 X2 的协作关系，目标是两个关系之间的最小距离

>[! note] 最小距离 
>关于最小距离，常用余弦距离，角度范围在 0-360 之间，余弦值在 -1～1 之间，因此范围比较固定，很稳定。但是欧氏距离是不可控的，会出现损失震荡，不易于模型的训练。

>[!note] 球面空间 （余弦距离通过反三角函数转换到球面空间～）
>相比于平面空间，稀疏性会更大一些
>第一象限到第四象限相当于 X 轴反转，在球面空间中相当于在一个类三角形中；在不同的位置，都能用一个类三角形表示


## 4.2 翻译
如何将数据从一种模式转换（映射）到另一个模式
难度：不仅数据是异构的，模态之间的关系是开放式或者主观的

### 4.2.1 常见应用
机器翻译：语言翻译、唇语阅读、语音翻译
图片或视频的描述：对给定媒体形成文字描述
	视频：描述多张图片之间语义的连贯性，难度是比较大的，信息很多常用跳帧处理（需要带一些随机性）、自注意力机制。 
语音合成：根据给定的文本自动合成语音信号
![[Pasted image 20240419214846.png|475]]
方法 A：基于实例化的翻译（传统的机器学习）
词袋模型，像查字典
方法 B：模型驱动（深度学习）
有训练阶段，根据训练好的模型，从源到目标
source和 target：比如中翻英，分别就是中文和英文
### 4.2.2 基于实例的方法
从词典中检索最佳翻译
词典：训练集中的数据对
检索包括单模态检索：以图搜图、关键字检索
也包括多模态检索：
![[Pasted image 20240419220109.png]]
多模态的“冗余性”更大：分类边界更模糊，返回的结果可选择性更多；目前的搜索都是模糊搜索。

### 4.2.3 模型驱动的方法
![[Pasted image 20240419220516.png]]
### 4.2.4 翻译的评估困境
评估是一个更上层的任务，底层的任务是解决翻译
![[Pasted image 20240419220813.png]]

3 对齐 alignment
从两种或多种不同的模态中识别子元素之间的直接关系

例如：将食谱步骤和正在制作的菜肴视频对齐

需要测量不同模式之间的相似性并处理可能的长期依赖（和 LSTM 很像，距离很长，记忆会依赖于近期内容）和歧义（一词多义、情景问答）

图片与句子的关联匹配 训练 


3.1显式对齐
模型目标是对齐来自两个或多个模态的子元素，大部分方法都依赖于度量不同模态的子组件之间的相似性

重要点：相似性度量：越相似的内容误差越小

包括无监督和弱监督两种方法
无监督对齐：对齐结果无确定标注，没有辅助信息告诉机器匹配的是否正确
有监督对齐：能够学习输入进去的标注

应用：步态识别；VR（把传感器贴到人的关节处，通过外在人的行为控制虚拟空间里的人的行为）

3.2隐式对齐
通常是一些人物中间步骤，允许在许多任务中有更好的表现，包括语音识别、机器翻译、媒体描述和视觉问题的回答，这些模型不显式地对齐数据，而是学习如何在模型训练期间，潜在地对齐数据

4 融合 Fusion
结合来自两个或多个模态的信息来执行预测
如：视听语音识别、嘴唇运动的视觉描述与语音信号融合以预测口语，来自不同的信息可能具有不同的预测能力和噪声拓扑、并可能在至少一种模态中丢失数据

法 1：两个模型输入，通过权重等方式融合
训练单个模型（早期融合）：多个模态数据来源不一，拼接难度大、对数据预处理很敏感
训练多个模型（晚期融合）：训练多个模型，在预测层（最后一层）融合有灵活性，但是没有利用模态之间底层特征的相关性（信息浪费了，没利用起来），并且计算复杂度大
混合融合：前融合和后融合，Hybird Fusion逐级融合方式，在不同层次上依次对不同模态进行融合（目前较多）

法 2：基于模型的融合

深度神经网络
多核学习
Graphical models: 利用隐马尔科夫或贝叶斯网络建模数据的联合概率分布（生成式、判别式）


生成器生成假图像，尽可能地让判别式误判
判别器要尽可能地即做出正确判断

Auto Encoder: 基于联合概率分布的生成式（伪生成：也会从原始数据中编码，只是利用了联合概率分布）


5协同学习 Co-learning

（目前处于概念层，不在实践层，和零样本训练差不多）

在模态表述和预测模型之间转移知识

协同学习探索了从一种模态中学习的知识如何帮助在不同模态上训练的计算模型，当其中一种模式 d 资源有限（例如带注释的数据） 辅助模态通常参与模型训练过程（起验证集的作用），并不参与测试使用过程。

Adapter(教师模型)：用大模型的参数辅助小模型来训练

做运算阶段：
做推理阶段：

5.1 并行
需要来自一种模态的观察结果与来自其他模态的观察结果直接相关

5.2 非并行
不需要来自不同模式的观察结果之间的直接联系（例如一些零样本学习）（吴恩达所在学校做的一个研究，利用医生检测报告中的信息来研究数据的标注）

5.3 混合 
共享模式或数据集桥接


00 SOTA 模型：CLIP
NLP 和 CV 结合的多模态工作，无需利用 imagenet 的数据和标签进行训练，利用无监督的文本信息，作为监督信号来学习视觉特征


1 原理：不预先定义图像和文本标签类别，直接利用从互联网爬去的数据集来
2 流程：
预训练：使用 图片-文本对 进行对比学习训练（提取特征，做距离度量，选择比较好的距离度量方式，优化理论（球面空间等等））
提取预测类别文本特征



方法、思路
问题、解决方法


问：为什么这么做，代码怎么写的，有没有做过sota 的对比
backbone
baseline